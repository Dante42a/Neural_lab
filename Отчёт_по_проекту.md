# Отчёт по проекту: Анализ заполненности зала по стульям с помощью искусственных нейронных сетей

## 1. Введение

В данном проекте рассматривается задача автоматического анализа заполненности зала по количеству занятых и свободных стульев на изображениях с использованием предобученных нейронных сетей YOLOv8 и YOLO-Pose.

## 2. Постановка задачи

Цель: определить количество занятых и свободных стульев на изображениях зала, визуализировать результаты и оценить качество работы модели.

## 3. Используемые технологии
- Python 3.9.6
- ultralytics (YOLOv8 + YOLO-Pose)
- OpenCV
- NumPy
- Roboflow Furniture Dataset 

## 4. Код для анализа заполненности зала

```python
from ultralytics import YOLO
import cv2
import numpy as np
import os

# Модели
pose_model = YOLO('yolov8n-pose.pt')  # для детекции людей
chair_model = YOLO('yolov8n.pt')      # для детекции стульев

# Классы COCO
CHAIR_CLASS_ID = 56
PERSON_CLASS_ID = 0

def analyze_hall_occupancy_simple(image_path, save_result=True):
    """Анализ заполненности зала"""
    img = cv2.imread(image_path)
    
    # Детекция стульев
    chair_results = chair_model(img)[0]
    chairs = []
    for box in chair_results.boxes:
        if int(box.cls) == CHAIR_CLASS_ID:
            chairs.append(box.xyxy[0].cpu().numpy())
    
    # Детекция людей
    pose_results = pose_model(img)[0]
    people = []
    for box in pose_results.boxes:
        if int(box.cls) == PERSON_CLASS_ID:
            person_bbox = box.xyxy[0].cpu().numpy()
            people.append(person_bbox)
    
    # Определение занятых стульев
    occupied_chairs = 0
    for chair in chairs:
        chair_center = [(chair[0] + chair[2])/2, (chair[1] + chair[3])/2]
        for person in people:
            person_center = [(person[0] + person[2])/2, (person[1] + person[3])/2]
            distance = np.sqrt((chair_center[0] - person_center[0])**2 + 
                             (chair_center[1] - person_center[1])**2)
            if distance < 150:  # порог расстояния
                occupied_chairs += 1
                break
    
    return {
        'total_chairs': len(chairs),
        'occupied_chairs': occupied_chairs,
        'free_chairs': len(chairs) - occupied_chairs,
        'total_people': len(people),
        'occupancy_rate': occupied_chairs / len(chairs) if len(chairs) > 0 else 0
    }
```

## 5. Подсчёт метрик

Для оценки качества работы модели используются следующие метрики:
- **Precision** — точность детекции стульев
- **Recall** — полнота детекции стульев  
- **IoU** — пересечение по объединению
- **Заполненность зала** — процент занятых стульев

## 6. Примеры результатов (скриншоты)

**Вставьте сюда 3–5 изображений с выделенными стульями и людьми.**

---

### Пример оформления (замените на свои скриншоты):

1. ![Скриншот 1](results_occupancy/your_image1.jpg)
   *Комментарий: Зелёные прямоугольники — стулья, красные — люди. Заполненность: 75%*

2. ![Скриншот 2](results_occupancy/your_image2.jpg)
   *Комментарий: Модель корректно определила стулья и людей, но есть ложные срабатывания*

3. ![Скриншот 3](results_occupancy/your_image3.jpg)
   *Комментарий: Пример пустого зала — все стулья свободны*

---

**Замените пути и комментарии на свои файлы и наблюдения.**

## 7. Метрики качества

- Precision: ...
- Recall: ...
- IoU: ...
- Средняя заполненность зала: ...%

## 8. Выводы

В ходе работы была реализована система для автоматического анализа заполненности зала с использованием двух предобученных моделей: YOLOv8 для детекции стульев и YOLO-Pose для детекции людей. Система позволяет определять количество занятых и свободных стульев, а также рассчитывать процент заполненности зала. Полученные результаты демонстрируют ... (дополнить по итогам экспериментов). 

---

## Ваши следующие шаги

### 1. Установите необходимые библиотеки (если ещё не установили):

```bash
pip install ultralytics opencv-python matplotlib
```

---

### 2. Проверьте структуру папки с изображениями

Пусть ваши изображения лежат, например, в папке `dataset/images/`.  
В коде укажите этот путь:

```python
IMAGES_DIR = 'dataset/images'
```

---

### 3. Запустите инференс и сохраните результаты

Используйте код из отчёта (раздел 4).  
Результаты (изображения с выделенными стульями) сохранятся в папку `results/`.

---

### 4. Получите метрики (если есть аннотации)

Если у вас есть файл аннотаций (например, `data.yaml` для YOLOv8), выполните:

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')
metrics = model.val(data='path/to/data.yaml', split='val')
print(metrics)
```
- Вставьте полученные значения precision, recall, IoU в отчёт.

---

### 5. Добавьте скриншоты

Выберите 3–5 наиболее показательных изображения из папки `results/` и вставьте их в раздел 6 отчёта.

---

### 6. Заполните выводы

В разделе “Выводы” опишите, насколько хорошо модель справляется с задачей, есть ли типичные ошибки (например, пропуски или ложные срабатывания).

---

Если возникнут вопросы по коду, аннотациям или оформлению — пишите!  
Готов помочь на любом этапе. 

---

Переходим к практической части: инференс с помощью предобученной YOLOv8 на датасете стульев, визуализация и сбор метрик.

---

## 1. Установка необходимых библиотек

```bash
pip install ultralytics opencv-python matplotlib
```

---

## 2. Пример кода для инференса и визуализации

```python
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import os

# Путь к папке с изображениями из датасета
IMAGES_DIR = 'path/to/your/images'  # замените на свой путь
RESULTS_DIR = 'results'
os.makedirs(RESULTS_DIR, exist_ok=True)

# Загрузка предобученной модели YOLOv8
model = YOLO('yolov8n.pt')  # Можно использовать yolov8s.pt для большей точности

# Класс "стул" в COCO — 56 (chair)
CHAIR_CLASS_ID = 56

# Обработка изображений
for img_name in os.listdir(IMAGES_DIR):
    if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
        continue
    img_path = os.path.join(IMAGES_DIR, img_name)
    img = cv2.imread(img_path)
    results = model(img)[0]
    chairs = [b for b in results.boxes if int(b.cls) == CHAIR_CLASS_ID]
    for b in chairs:
        x1, y1, x2, y2 = map(int, b.xyxy[0])
        cv2.rectangle(img, (x1, y1), (x2, y2), (0,255,0), 2)
        cv2.putText(img, 'Chair', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)
    # Сохраняем результат
    cv2.imwrite(os.path.join(RESULTS_DIR, img_name), img)
    # Для отчёта — визуализация первых 3 изображений
    if img_name in os.listdir(IMAGES_DIR)[:3]:
        plt.figure(figsize=(8,6))
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f'Detected chairs: {len(chairs)}')
        plt.axis('off')
        plt.show()
```

---

## 3. Подсчёт метрик (если есть аннотации)

Если у вас есть аннотации (YOLO/COCO), можно использовать встроенные функции оценки в ultralytics:

```python
# Оценка на валидационном наборе
metrics = model.val(data='path/to/dataset/data.yaml', split='val')
print(metrics)
```
- Вы получите значения precision, recall, mAP, IoU и др.

---

## 4. Для отчёта

- Сохраните 3–5 изображений с выделенными стульями (скриншоты).
- Скопируйте метрики (precision, recall, IoU).
- Добавьте краткое описание процесса и выводы.

---

## 5. Шаблон отчёта

Я подготовлю для вас шаблон отчёта с местами для вставки кода, метрик и скриншотов.  
Если потребуется — помогу с оформлением .docx.

---

**Если возникнут вопросы по коду или потребуется помощь с аннотациями/метриками — пишите!**  
Когда получите результаты — отправьте метрики и скриншоты, и я помогу оформить финальный отчёт. 